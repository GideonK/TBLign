#!/usr/bin/perl -w
use strict;
use FindBin qw($Bin);
use lib $FindBin::Bin.'/../lib';
use List::Util qw[min max];
use Getopt::Std;

use vars qw/$opt_d $opt_l/;
getopt('dl');

unless (defined $ARGV[0]) {
  die ("No score file specified!");
}
unless (defined $opt_l) {
  die ("No output file with levels (-l) specified!");
}
unless (defined $opt_d) {
  die ("No output file with cutoff scores (-d) specified!");
}

open (IN, "<$ARGV[0]") || die ("Could not open scores file ($ARGV[0])!");
open (LOUT, ">$opt_l") || die ("Couldn't open output file with levels ($opt_l)!");
open (DOUT, ">$opt_d") || die ("Couldn't open output file with cutoff scores ($opt_l)!");

my $max=0;
my $score;
my $linecount=-1; ## rule counts begin at 0
my $returnline=0;
my @lines=();

while (my $in=<IN>) {
  if ($in =~ /(\S+)\t\S+$/) {
    push(@lines,$in);
    $linecount++;
    $score=$1;
    $score =~ s/,/\./g;
    if ($score > $max) {
      $max=$score;
      $returnline=$linecount;
    }
    elsif ($score == $max) {
      $returnline=$linecount;
    }
  }
}

print DOUT "Precision (all)\tRecall (all)\tRecall (good)\tRecall (fuzzy)\tF-score (P_all & R_all)\tF-score (P_all & R_good)\n";

for (my $i=0; $i<=$returnline; $i++) {
  if (defined $lines[$i]) {
    print DOUT $lines[$i];
    print LOUT "$i\n";
  }
  else {
    warn ("Defined line $i expected in array \@lines!\n This may lead to the wrong rules being applied when the output file is used. Check code.\n");
  }
}

close (DOUT);
close (LOUT);

__END__

=head1 DESCRIPTION

This script is used automatically by the tree alignment tool TBLign, which implements transformation-based learning. It takes as input a text file containing a list of evaluation scores as produced by eval-nonterms.pl (evaluating non-terminal alignment). Each score is the evaluation result of the application of a learned rule. Each line in this list contains some columns. The last two columns are F-scores (P_all & R_all and P_all & R_good, where P refers to Precision and R to Recall, and all refers to all types of links, and good only to good (confident) links (not fuzzy (less confident)). We will look at the second last column (P_all & R_all) and return the line containing the highest F-score. The idea is that we only want to cut off the learned set of rules at the point where it has led to the highest score, in order to minimize overtraining. If there is more than one highest F-score (in other words, if this highest F-score also occurs elsewhere), we return everything up to the last line containing this score. The rule which corresponds to this score/line is the last rule to be applied on the test set or on new data.

=head1 AUTHOR

Gideon KotzE<eacute>, E<lt>gidi8ster@gmail.comE<gt>

=cut
